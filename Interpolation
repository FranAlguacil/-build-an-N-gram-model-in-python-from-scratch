
    def sentence_interpolated_logP(self, sentence, lambdas=[0.5, 0.3, 0.2]):
      tokens = ['*', '*'] + sentence + ['</s>']
      prob = 0
      total_ngrams = sum(self.ngram_counts.values())
      for u, v, w in nltk.ngrams(tokens, 3):
          uni_prob = np.log((self.ngram_counts.get((w,), 0) + 1) / (total_ngrams + len(self.vocab)))
          bi_prob = np.log((self.ngram_counts.get((u, v), 0) + 1) / (self.ngram_counts.get((u,), 0) + len(self.vocab)))
          tri_prob = np.log((self.ngram_counts.get((u, v, w), 0) + 1) / (self.ngram_counts.get((u, v), 0) + len(self.vocab)))
          prob += lambdas[0] * tri_prob + lambdas[1] * bi_prob + lambdas[2] * uni_prob
      return prob
