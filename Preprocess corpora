 As seen in class, I figured out it is easier to implement a corpus from NLTK than other. The code will more legible and short and it is less problematic.
    
    #BROWN
    import nltk
    import numpy as np
    nltk.download('brown')
    corpus = nltk.corpus.brown
    sentences = corpus.sents(categories='news')
    tokenized_sentences = [[w.lower() for w in sent] for sent in sentences]
    
    #REUTERS
    import nltk
    import numpy as np
    nltk.download('punkt')
    nltk.download('reuters')
    from nltk.corpus import reuters
    corpus = nltk.corpus.reuters
    sentences = reuters.sents()
    tokenized_sentences = [[w.lower() for w in sent] for sent in sentences]
    
    #ABC
    import nltk
    import numpy as np
    nltk.download('abc')
    from nltk.corpus import abc
    corpus = nltk.corpus.acbc
    sentences = abc.sents()
    tokenized_sentences = [[w.lower() for w in sent] for sent in sentences]
    


